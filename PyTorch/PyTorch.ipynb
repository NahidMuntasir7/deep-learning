{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic"
      ],
      "metadata": {
        "id": "IrbssDry7zK0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeW6h9cW3Sb3"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar\n",
        "a = torch.tensor(5)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1eFoPle4abW",
        "outputId": "ecffcdfd-d73a-4e22-ad1b-01b7d2c62416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "b = torch.tensor([1, 2, 3])\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-zWTVjx4ecD",
        "outputId": "80af4e20-196e-45cd-a914-3c174b125a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix\n",
        "c = torch.tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdZ2yiX24h5N",
        "outputId": "f2c0e4b4-f456-4a22-d135-7a8570fc1dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(x.dtype)  # torch.int64 by default for integers\n",
        "\n",
        "y = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(y.dtype) # torch.float32 by default for floats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOY7jXmb7oWy",
        "outputId": "e54cc74a-12e9-4ce2-ebbd-9b0556cae144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor Properties\n",
        "\n",
        "print(c.shape)      # size\n",
        "print(c.dtype)      # data type\n",
        "print(c.device)     # cpu or gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO_IbAJU4krO",
        "outputId": "d03e1235-a0b2-4b6b-901b-7ba2d1bff191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.int64\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK IF GPU IS AVAILABLE\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flYnxNso6Pou",
        "outputId": "584b4f02-4b7e-4fed-aeaa-bf740f969b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting Device\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "torch.cuda.get_device_name(0)\n",
        "# torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bdt8yVra6Zwg",
        "outputId": "dcbd372f-28cc-4dd4-b5a6-0876358dbae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MOVE TENSOR TO DEVICE\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x = x.to(device)\n",
        "\n",
        "print(x.device)\n",
        "\n",
        "# MOVE MODEL TO DEVICE\n",
        "\n",
        "# model = MyModel()\n",
        "# model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MywZAEwd6e3V",
        "outputId": "f4163e13-ce88-481e-c95f-ad0872532e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FULL STANDARD TEMPLATE\n",
        "\n",
        "# import torch\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # model\n",
        "# model = MyModel().to(device)\n",
        "\n",
        "# # data\n",
        "# inputs = inputs.to(device)\n",
        "# labels = labels.to(device)\n",
        "\n",
        "# # training\n",
        "# outputs = model(inputs)\n",
        "# loss = criterion(outputs, labels)\n",
        "\n",
        "# -------------------------------------\n",
        "# WHY DEVICE SELECTION MATTERS\n",
        "\n",
        "# Forget .to(device) → runtime error\n",
        "\n",
        "# CPU training → very slow\n",
        "\n",
        "# GPU mismatch → crash\n",
        "\n",
        "# Every PyTorch bug beginner faces = device mismatch\n",
        "# -------------------------------------\n",
        "\n",
        "# device = \"cuda\"\n",
        "\n",
        "# x = torch.rand(3, 3)\n",
        "# y = torch.rand(3, 3).to(device)\n",
        "\n",
        "# z = x + y   # error"
      ],
      "metadata": {
        "id": "UKKZJXP_68gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Common Tensor Creation\n",
        "\n",
        "torch.zeros(3, 4)\n",
        "# torch.ones(2, 2)\n",
        "# torch.rand(3, 3)\n",
        "# torch.randn(3, 3)   # normal distribution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOzOVbr45CfW",
        "outputId": "fd49bf91-0c66-4457-f6d7-292f6319a826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy vs PyTorch\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np_array = np.array([1, 2, 3])\n",
        "torch_tensor = torch.from_numpy(np_array)\n",
        "torch_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNzbQpHk5i3J",
        "outputId": "052e2f44-1c52-4796-af87-db89a0da87ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x = torch.rand(2, 3)\n",
        "# y = torch.rand(3, 2)\n",
        "# x + y # error (size nismatch)\n",
        "\n",
        "x = torch.rand(2, 3)\n",
        "y = torch.rand(2, 3)\n",
        "x + y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CCsaSen5uf-",
        "outputId": "0f56f069-7c8d-448d-c8b9-9d300e9ad360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0947, 1.1413, 0.1232],\n",
              "        [0.7518, 0.8889, 1.1640]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor operations, indexing & broadcasting"
      ],
      "metadata": {
        "id": "stOJbfcl7lzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. BASIC TENSOR OPERATIONS\n",
        "\n",
        "import torch\n",
        "\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "print(a + b)\n",
        "print(a - b)\n",
        "print(a * b)\n",
        "print(a / b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o1dzASZ54yb",
        "outputId": "00521220-88f8-4f2d-8e37-362e87791b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n",
            "tensor([-3., -3., -3.])\n",
            "tensor([ 4., 10., 18.])\n",
            "tensor([0.2500, 0.4000, 0.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mismatch error example\n",
        "x = torch.tensor([1.0,2.0])\n",
        "y = torch.tensor([1,2])\n",
        "print(x + y)  # Error: float + int\n",
        "\n",
        "# Solution: cast tensors to same dtype\n",
        "y = y.float()\n",
        "\n",
        "# CHANGE DTYPE\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x = x.float()     # to float32\n",
        "x = x.double()    # to float64\n",
        "x = x.long()      # to int64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqJ_jZcA71BV",
        "outputId": "70da8cc5-32d5-43c6-b6e0-80c3e1e818ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. SCALAR OPERATIONS\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "\n",
        "print(x + 2)\n",
        "print(x * 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCuqh8lZ747L",
        "outputId": "49bbf794-a099-4749-d5a5-52d25002c94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 4, 5])\n",
            "tensor([3, 6, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. MATRIX MULTIPLICATION (VERY IMPORTANT)\n",
        "\n",
        "# Wrong (element-wise):\n",
        "A = torch.rand(2, 3)\n",
        "B = torch.rand(3, 2)\n",
        "\n",
        "# A * B    # ERROR\n",
        "\n",
        "# Correct (matrix multiplication):\n",
        "\n",
        "torch.matmul(A, B)\n",
        "# or\n",
        "A @ B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVjCUaYp8Bgm",
        "outputId": "fd495820-faf0-483c-ec41-38c470c5ebd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6847, 1.0395],\n",
              "        [1.0930, 1.3131]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. RESHAPING TENSORS\n",
        "\n",
        "# What they are\n",
        "# Both change the shape of a tensor without changing data.\n",
        "# Difference\n",
        "# view() → works only if memory is contiguous\n",
        "# reshape() → safer, works even if memory is not contiguous\n",
        "# In simple words\n",
        "# view() = “reshape if possible”\n",
        "# reshape() = “reshape no matter what”\n",
        "# Use reshape() in practice\n",
        "\n",
        "x = torch.rand(2, 3)\n",
        "print(x)\n",
        "y = x.view(3, 2) # view() needs contiguous memory\n",
        "print(y)\n",
        "\n",
        "y = x.reshape(3, 2) # Safer than view\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3qbNDPk8mKl",
        "outputId": "1e9e7d84-b145-4c0c-fd22-75b12cd96c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7829, 0.3784, 0.7882],\n",
            "        [0.6629, 0.6213, 0.1066]])\n",
            "tensor([[0.7829, 0.3784],\n",
            "        [0.7882, 0.6629],\n",
            "        [0.6213, 0.1066]])\n",
            "tensor([[0.7829, 0.3784],\n",
            "        [0.7882, 0.6629],\n",
            "        [0.6213, 0.1066]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. UNSQUEEZE & SQUEEZE\n",
        "# unsqueeze\n",
        "# Adds a dimension of size 1\n",
        "# Example meaning:\n",
        "# Vector → Row / Column\n",
        "# Needed for batching & model input\n",
        "# Think:\n",
        "# “I need one more bracket”\n",
        "\n",
        "# brackets = dimensions\n",
        "\n",
        "# [  [ 1,  2,  3 ]  ]\n",
        "#  ↑        ↑\n",
        "#  row     columns\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(x)\n",
        "\n",
        "x = x.unsqueeze(0)  # shape: (1,3)\n",
        "print(x)\n",
        "\n",
        "x = x.unsqueeze(1)  # shape: (3,1)\n",
        "print(x)\n",
        "\n",
        "# Remove dimension\n",
        "x = x.squeeze()\n",
        "print(x)\n",
        "\n",
        "# squeeze\n",
        "# Removes dimension(s) of size 1\n",
        "# Example meaning:\n",
        "# Model output cleanup\n",
        "# Removing useless dimensions\n",
        "# Think:\n",
        "# “Remove extra bracket”"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBu-v1Ll9ED6",
        "outputId": "c583759b-9e90-4aa7-fe7a-a4bcce121c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([[1, 2, 3]])\n",
            "tensor([[[1, 2, 3]]])\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. INDEXING & SLICING\n",
        "\n",
        "x = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "\n",
        "print(x[0])        # first row\n",
        "print(x[:, 1])     # second column\n",
        "print(x[0, 2])     # element"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ilx4ZXZ9aNM",
        "outputId": "e8e20b8e-a0a0-4b5e-d582-fdeca47fc33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([2, 5])\n",
            "tensor(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. BOOLEAN MASKING\n",
        "\n",
        "x = torch.tensor([1, 5, 3, 8, 2])\n",
        "\n",
        "mask = x > 3\n",
        "print(x[mask])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7Mw-BlT9rOF",
        "outputId": "284f1fd5-ff4b-4566-9aee-bdec71285c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. BROADCASTING\n",
        "\n",
        "x = torch.rand(2, 3)\n",
        "b = torch.rand(3)\n",
        "\n",
        "y = x + b\n",
        "print(y)\n",
        "\n",
        "# # PyTorch automatically expands smaller tensor.\n",
        "# A = torch.rand(4, 3)\n",
        "# b = torch.tensor([1, 2, 3])   # shape (3)\n",
        "\n",
        "# A → (4, 3)\n",
        "# b → (3)\n",
        "\n",
        "# PyTorch auto-expands b to:\n",
        "# [[1, 2, 3],\n",
        "#  [1, 2, 3],\n",
        "#  [1, 2, 3],\n",
        "#  [1, 2, 3]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xlX7Ua695OV",
        "outputId": "e3c3a349-bd5e-42fb-b2ba-8d3e5e320816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.3838, 1.5899, 1.2411],\n",
            "        [1.1905, 1.6917, 1.3243]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AUTOGRAD & BACKPROPAGATION (CORE CONCEPT) - Heart of PyTorch"
      ],
      "metadata": {
        "id": "7--s6IHjBBrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHAT IS AUTOGRAD?\n",
        "\n",
        "Autograd is PyTorch’s automatic differentiation engine. It automatically computes gradients:\n",
        "\n",
        "\n",
        "You do not write derivative formulas.\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH4AAABBCAYAAAAXDxDwAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAA1vSURBVHhe7Zx7TFP3+8dfpdxroxKBik4uWquoOELYxExi4wzK0k2N16FRplMmiwpzqJniZZLhvsY559QpblPAGzE2MnFzcRJ1ukwQLS4QGnFc1IIIYldpbUt/f/zkhNZ5hThI+0r6R5/n85zP6Xmfz+2cz1NRaGioDRdOh5ujwYVz4BLeSXEJ76S4hHdSXMI7KS7hnRSX8E6KS3gnxSW8kyLqzk/uYmNjmTVrFsHBweh0Og4fPswvv/wi+CUSCWPGjKG5uZmLFy/axTo73bbFp6amkpGRQW1tLT/88AMPHz5k06ZNpKamArB37140Gg07duwgOTnZMdzp6ZbCx8TEMHXqVCorK9m6dSt5eXkkJSVRXFzM7NmzUalUzJ8/n4yMDFpaWhzDXXRX4aOjo/Hz8yM4OJiBAwcK9mvXruHr68tbb70FQFNTE62tre0iXbTRLYU/cuQIWVlZpKeno9Fo7HwikYh+/frZ2Vw8Tred3MXGxrJ06VJCQkIwmUxcuHCBuro6FixYwJUrV5gxYwaTJ09mw4YNXL16ldmzZ9vFx8XFERcXR2BgIEVFRRw8eBCdTif45XI5M2bMQC6XU1tbi06no7m5mf379wMwatQoVCoV/fv3R6vV0tLSQnl5OSdOnGhXS9elW7b4tLQ0tm/fTn19Pe+88w5TpkzB39+fuLg4PDw8MJvNjiECEomE7du3s3HjRpqamigoKGDMmDEcPXqUSZMmAaBSqdi3bx9SqRS1Wk1raysLFy4kPDwcgEWLFrF161aam5tRq9XIZDLmzZvH4MGDHWrrunQ74ZcvX05iYiIajYaPPvoInU6HTqfj9OnTyGQybDYbVVVVjmECaWlpjBs3DrVazeeff05ubi4rVqzAZDKRkpJCZGQko0aNQiQSkZ+fz7Fjx1izZo3dcnD06NHo9Xq+/fZbjh07xscff0x5ebldPV2dbiV8ZGQkKpUKq9XKqVOn7Hx6vR6bzUZLSwtlZWV2vjYiIiJQKpW0tLRQUlIi2LVaLbdu3SIoKIiJEydisVjo06cP69atY/369SiVSrZv386BAwcAMJlMhISEcPDgQZYvX05MTAxffvklP/30U7vaujbdSvixY8cik8lobGzkypUrdr6wsDA8PT25efMmx44ds/O1ERISQs+ePTEajTQ1NTm6EYvFKBQKcnJyuHbtGqGhocyZM4esrCy2bNmCn58fAAcOHKCmpobhw4ezePFicnJyWLlypePhujTdSvjAwEA8PDyoqal5bDYfHh6OSCTi7NmzGAwGO18bFosFq9WKh4cHvr6+jm4Ampub0Wq1TJ48mZSUFNRqNVVVVYSGhpKSkoJEIqGwsBCVSsWaNWs4efIkdXV1jBw5krS0NMfDdVm6lfBt1NTU2H0fO3YsI0aM4MaNGxw5csTO156ysjIaGxvx8fERWm8b3t7emEwmysrKyMzMJCcnh+PHj5OamopKpeLy5cv4+/sTERFBdnY26enp5ObmkpyczNy5c6murmbAgAF2x+zKdCvhr127xoMHD/D39xdsMpmMDz/8ELFYzP79+9FqtXYx7blx4wb5+fm4ubkRGxsr2OPi4ggODqaiokJYrikUCuLi4gAwGAzcv38fvV6PRqNBJBIRHR2NXC4H4NatWxgMBu7cuSMcs6vT7dbx//vf/4iPj6e0tJT6+noiIyOxWCx8/fXXqNVqodyePXsYM2YMnp6e2Gw2Ghoa2LhxI/n5+SQlJZGYmIjRaKSlpYWAgAD++usvNmzYgFarJTMzk/Hjxwtxnp6eeHl5CY+Hs7OzUSgUADQ0NODr64vZbCYjI4PCwsJ2Z9t16XbC86iFKpVK3NzcuHr1Kmq1+onj+tNQKpVIpVLKysrseoohQ4ZgtVrR6/VER0fzzz//cObMGcEfFRXFzZs3kUqlDB06lDt37nS7t3/dUngXHadbjfEuOg+X8E6KS3gnxSW8k+IS3klxCe+kdGg5V1lZ6Why8YoJCwtzND0XHRLeRffF1dU7KS7hnRSX8E5Kp47xz0ppctF1EPfu3Xudo/FlSE1NJTk5mcuXL3P69GmCg4NJTEzE19e32725cgY6pat/npQmZyciIoKdO3eiVCodXf8JnSL886Y0OTP9+/dn2LBh9OrVy9H1n9ApwrtSmp5NZGQkPXr0cDT/Z3Ta5O5ZKU27du0iKCiIESNGUFRUREVFBe+99x4SiYQzZ848NglsS2FSKBSYTCYuXrzIoUOHhJ02crmcoUOHMnjwYHx8fDh//jxKpZKqqiq7cjNnzmTUqFEEBQWh1WrJz8/njz/+EOpRKpXPPC+ZTMasWbPo27fvE3f8REZGMn36dAYOHEhFRQVHjx4V9u4nJCSwbNkyfHx82L17NzU1Neh0Oru5z5Pi23L8g4KCkMvlnDt3DoVCgUQi4fDhw0/dY/g0OkX4tLQ0Zs+eze+//8769esB2LRpE/369SMsLIwLFy5gsViIjo7Gx8eHu3fvYjAY0Gg0wkU/f/48S5YswWAwEBkZydatW/H19WXnzp307NmThIQE6urqWLZsGVqtloSEBJKTk/H390ev13Pv3j2sVishISEcOHCAtWvXsn79embNmkVhYSG//vorkyZNYuTIkXz//fds2bIFgB9//JE333wTLy8vLl++LGzFCgsLY9CgQRQUFPD6669z/fp1fH19eeONN7hw4QKJiYnC71+0aBELFy6kvLycU6dOMW3aNPr27SvUMWPGDEJCQvD29qaqqgqz2UxJSQmfffbZM+NLS0tZt26dsH28trYWo9HIoEGDKC8v5/3333/sJnweOtzVP29K07x588jKysJsNlNbW8vMmTNZsmQJc+fORaPREBsbK+xL79mzJz4+Pnh6etLQ0MBXX33FyZMnGTx4MAsWLAAgNzeX0aNHU1lZiVQqpbCwkKKiIu7fv8/du3cB6NWrF2KxGC8vL/Ly8ti8eTNNTU1MnTqVmJgYALvzCgwMZOXKlSxbtozs7GxaW1uZMGECOTk5LFq0iPT0dG7duoVCoRDiY2JimDt3Lk1NTaxevZp9+/axe/du3NzcmDZtGrm5ubz77rvcvn0bk8nEjh07iI+PF0R/VrxGo2HKlCmo1Wo8PDy4d+8e2dnZNDY2Cg3oZeiQ8C+b0mQwGITMVIPBwG+//YbFYiE2NpbQ0FAKCwtZunQpSUlJHD9+HIDGxkZaW1v/db5gNBopLS1l1apVREVFsW3bNgC++OILkpOTWbFiBQAlJSU8ePAAqVSKTCYT4tty6MvKyoTu2WKxYLPZuH37Nnl5efBoe/bDhw+FOIAJEyYQEBBAZWUlN27cAOD06dM0NDQQEBAg3CBP4kXjtVothw4dIiYmhg8++MDO9yJ0SPiOpjS1odPpsFgs9OjRQ3jbZDQamT9/PsXFxRQXFzNp0iTEYrFj6FPR6XSEhISQk5NDaWkphYWF9O3b17GYQGNjo6OJ1tbWp7aqgQMH4ubmxrBhwygoKKCgoIC8vDzMZjPXr19/aiydEP+ydEj4jqY0OWK1WjGZTEyePJnvvvuOkSNHsmXLFqKiolCr1VitVscQeNS7tM9tb2PPnj2kpKRQXV3N+PHjGTt2LLdv33Ys1iEePHgAQHFxMfHx8XafOXPmPHZdeNRTfvrpp4SGhr5QvNlspq6urt2RXp4OCd/Gy6Y0tSGXy/Hy8uLOnTuUlJQwceJE/Pz8+Pnnn8nNzXUszrZt21i8eLGj2Y74+HiioqKor6/nm2++eezGeO2118jOzrazvQwlJSWYTCaCgoLs7HK5nFWrVhEaGmpn51Hy5ttvv41MJnup+M6gQ8K/bEqTv7+/kH4kl8sZN24cFouFEydOCL2DSCTC09NTiAkPD8fd3R0APz8/vLy8BJ9EIrE7h/aIxWK8vb3h0R8etJWTSCRC4qSb2/9fhucdSry9venduzcA+/fvp6KigiFDhrBw4UKhzPTp0xk+fDj19fXwqFcSiURIpVKkUilGoxGdTvfc8QDu7u706dNH+N4ROryce96UJoCUlBSSkpK4e/cuNpuN5uZmZDIZVquVXbt2sXfvXnjUY6xevZp+/fpRXV2Nu7s7f//9NwEBASgUCmpra/nzzz+ZMGECUqkUkUjEw4cPqa2tZdWqVVy6dAmAjIwMpkyZQnNzM/fu3cPd3Z2ioiJUKhU2m438/HzCw8MJDw9HLBYLK5CbN28SHR0tpF/p9XrOnj1LbGysXX2HDx9m7dq1yOVy0tPTiYqKQqfTYbPZMJvNZGZmCilVCQkJfPLJJ5jNZoxGI/n5+WzevBke3fxPijcYDGRmZjJgwADEYrGQ4ZOVlcWOHTvaXd0Xo8PC8wIpTW3CX7p0ieXLlxMdHY3ZbObcuXP/Wj4mJgaZTMb169eFsS4iIuJfx80nIZPJHqunLau1urrasXiHaHuopNfr7VKu2mg7l6qqqn/9Dc+K70w6Rfjnpb3wjn9G5OLV0qEx/kVQKpUEBgbi5uaGVCpFpVLZraVdvFpemfDTp08nIiICrVaLh4cH8+bNY+jQoY7FXLwiXmlX76Lr8MpavIuuhUt4J8UlvJPiEt5JcQnvpLiEd1JcwjspLuGdFJfwTsr/AUrAXPZ8e5QrAAAAAElFTkSuQmCC)\n",
        "\n",
        "WHY DO WE NEED GRADIENTS?\n",
        "\n",
        "Training a neural network means:\n",
        "\n",
        "-> Change weights\n",
        "\n",
        "-> To reduce loss\n",
        "\n",
        "-> Using gradients\n",
        "\n",
        "-> Gradient tells:\n",
        "\n",
        "“Which direction should weights move to reduce error”"
      ],
      "metadata": {
        "id": "u6fG3UK8BTkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad=True\n",
        "# Meaning: “Track all operations on x for backprop”\n",
        "# Only tensors with requires_grad=True get gradients.\n",
        "\n",
        "import torch\n",
        "\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyjYcw6tBIE8",
        "outputId": "876a3a63-be10-48a1-99a6-603147bc39a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2., requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x * 3\n",
        "z = y ** 2\n",
        "\n",
        "# Graph: x → y → z\n",
        "# PyTorch remembers every operation."
      ],
      "metadata": {
        "id": "YZwjSj5yCKz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BACKPROPAGATION: .backward()\n",
        "\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCbeEUtRCaa1",
        "outputId": "fe30a476-63d3-4611-b535-b09247682e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "AXdbgeuCDDzL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> GRADIENT IS STORED IN .grad\n",
        "\n",
        "-> Gradient stored in leaf tensors\n",
        "\n",
        "-> x.grad holds result\n",
        "\n",
        "-> Intermediate tensors don’t keep gradients by default"
      ],
      "metadata": {
        "id": "PIJecskOFZkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # GRADIENT ACCUMULATION (BIG SOURCE OF BUGS)\n",
        "\n",
        "z.backward()\n",
        "z.backward()\n",
        "print(x.grad)\n",
        "\n",
        "# # Gradients add up\n",
        "\n",
        "# # So in training this is mandatory.\n",
        "\n",
        "optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "xiREYgMMDEfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SCALAR RULE: .backward() works only on scalars\n",
        "\n",
        "y = x * 3\n",
        "y.backward() # Wrong\n",
        "\n",
        "# Correct:\n",
        "\n",
        "y.sum().backward()"
      ],
      "metadata": {
        "id": "ViRAJ9PSEDrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TURN OFF AUTOGRAD (INFERENCE)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y = model(x)\n",
        "\n",
        "# Why?\n",
        "# Faster\n",
        "# Less memory\n",
        "# No gradients needed\n",
        "\n",
        "# Because we don’t want PyTorch to track weight updates in the computation graph or compute gradients\n",
        "# for them, which saves memory and prevents wrong gradient calculations."
      ],
      "metadata": {
        "id": "oaEeUM8IETAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "requires_grad=True → track gradients\n",
        "\n",
        ".backward() → compute gradients\n",
        "\n",
        ".grad → stores gradient\n",
        "\n",
        "zero_grad() → reset gradients\n",
        "\n",
        "no_grad() → inference mode"
      ],
      "metadata": {
        "id": "0qYC5NpFEjKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MINI PRACTICE\n",
        "\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "y = x * x * x   # x³\n",
        "y.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArvyjVpEEgZK",
        "outputId": "3ae6beb9-7252-4415-a0b9-a56a5c5bd9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LINEAR REGRESSION FROM SCRATCH"
      ],
      "metadata": {
        "id": "txnK1YLDFlXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement\n",
        "\n",
        "We want to learn: y=wx+b from data."
      ],
      "metadata": {
        "id": "PUyrmFrvF1QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE DUMMY DATA\n",
        "\n",
        "import torch\n",
        "\n",
        "# y = 2x + 1\n",
        "x = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
        "y = torch.tensor([[3.0], [5.0], [7.0], [9.0]])\n",
        "\n",
        "# Shapes:\n",
        "# x → (4,1)\n",
        "# y → (4,1)"
      ],
      "metadata": {
        "id": "RoxwnVQ5FwuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INITIALIZE PARAMETERS (LEARNABLE)\n",
        "\n",
        "w = torch.randn(1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "8vd1hCaQGHkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2963cc27-6135-45a1-82ae-07ba702947c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.8244], requires_grad=True)\n",
            "tensor([0.7627], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FORWARD PASS\n",
        "\n",
        "y_pred = w * x + b\n",
        "\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h74LjPFXGV1r",
        "outputId": "0613a8b7-f800-416e-ff5d-78577822c720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0616],\n",
            "        [-2.8860],\n",
            "        [-4.7103],\n",
            "        [-6.5347]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS FUNCTION (MSE)\n",
        "\n",
        "loss = ((y_pred - y) ** 2).mean()\n",
        "# Loss is scalar"
      ],
      "metadata": {
        "id": "hzqk6CkxGf1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BACKWARD PASS\n",
        "\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "ep8ePrJaGroz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now these contain gradients.\n",
        "print(w.grad)\n",
        "print(b.grad)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRoXDLsQGzuK",
        "outputId": "6be03dc2-b189-48a3-dcbc-0513f6a9fb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-58.5515])\n",
            "tensor([-19.5963])\n",
            "tensor([-1.8244], requires_grad=True)\n",
            "tensor([0.7627], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE PARAMETERS (GRADIENT DESCENT)\n",
        "\n",
        "lr = 0.01\n",
        "with torch.no_grad():\n",
        "    w -= lr * w.grad\n",
        "    b -= lr * b.grad"
      ],
      "metadata": {
        "id": "gJ1x14yLHN2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RESET GRADIENTS\n",
        "\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP8u46XkHS93",
        "outputId": "db1ba6f5-5390-498d-95e5-5fe9ea7e8a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do we use: with torch.no_grad(): during weight update?\n",
        "\n",
        "Because we don’t want PyTorch to track weight updates in the computation graph or compute gradients for them, which saves memory and prevents wrong gradient calculations.\n",
        "\n",
        "=> Because without torch.no_grad(), the **weight update itself becomes a differentiable operation**, so the next backward pass computes gradients through the update step, mixing old gradients + update math, which means the gradient is no longer the true ∂loss/∂w."
      ],
      "metadata": {
        "id": "qxx2T9nJIu5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FULL TRAINING LOOP\n",
        "\n",
        "import torch\n",
        "\n",
        "# y = 2x + 1\n",
        "x = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
        "y = torch.tensor([[3.0], [5.0], [7.0], [9.0]])\n",
        "\n",
        "# Initialize Parameter (Learnable)\n",
        "w = torch.randn(1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "for epoch in range(5000):\n",
        "    y_pred = w * x + b  # Forward Pass\n",
        "    loss = ((y_pred - y) ** 2).mean() # Loss Calculation\n",
        "\n",
        "    loss.backward() # Backward Pass\n",
        "\n",
        "    lr = 0.01\n",
        "    with torch.no_grad(): # Weight Update\n",
        "        w -= lr * w.grad\n",
        "        b -= lr * b.grad\n",
        "\n",
        "    w.grad.zero_() # Gradient Reset\n",
        "    b.grad.zero_()\n",
        "\n",
        "print(w.item(), b.item())\n",
        "\n",
        "# Expected:\n",
        "# w ≈ 2\n",
        "# b ≈ 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4IPhxS7HdBb",
        "outputId": "b6119af8-ac72-4c62-8cf9-7ebb65444e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2384], requires_grad=True)\n",
            "tensor([0.0496], requires_grad=True)\n",
            "2.000007390975952 0.9999802112579346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">WHAT YOU JUST LEARNED (VERY IMPORTANT)\n",
        "\n",
        "-> Forward pass\n",
        "\n",
        "-> Loss computation\n",
        "\n",
        "-> Backward pass\n",
        "\n",
        "-> Weight update\n",
        "\n",
        "-> Zeroing gradients\n",
        "\n",
        "This is every deep learning training loop, even for BERT.\n",
        "\n",
        ">COMMON MISTAKES\n",
        "\n",
        "-> Forget zero_grad()\n",
        "\n",
        "-> Update weights without no_grad()\n",
        "\n",
        "-> Wrong tensor shapes"
      ],
      "metadata": {
        "id": "t-RSazlIH7Vp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LESSON 5: nn.Module — HOW REAL MODELS ARE BUILT"
      ],
      "metadata": {
        "id": "d-nmf_dlhXH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHY nn.Module?\n",
        "\n",
        "Because manually managing: weights, gradients, parameters does not scale.\n",
        "\n",
        "nn.Module: registers parameters automatically, handles .to(device), integrates with optimizers\n",
        "\n",
        "--->\n",
        "\n",
        "WHY nn.Module?\n",
        "\n",
        "nn.Module is the base class of all PyTorch models.\n",
        "By inheriting from it, your class gets:\n",
        "Parameter tracking (weights, bias),\n",
        ".parameters(),\n",
        ".to(device),\n",
        ".train() / .eval(),\n",
        "Saving & loading support,\n",
        "Autograd integration.\n",
        "Without nn.Module, PyTorch cannot treat this as a model.\n",
        "\n",
        "--->\n",
        "\n",
        "WHY super()?\n",
        "\n",
        "This calls the constructor of nn.Module.\n",
        "Why important?\n",
        "Because nn.Module:\n",
        "Sets up internal machinery,\n",
        "Enables parameter registration,\n",
        "Enables hooks, buffers, state_dict.\n",
        "Forget super() → model breaks silently"
      ],
      "metadata": {
        "id": "lPSHCUp-huzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SIMPLE LINEAR MODEL USING nn.Module\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
        "y = torch.tensor([[3.0], [5.0], [7.0], [9.0]])\n",
        "\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self): # Define layers, Initialize parameters, Set model structure\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(1, 1) # 1 input, 1 output\n",
        "\n",
        "    def forward(self, x):  # PyTorch automatically calls this when you do: output = model(x)\n",
        "        return self.linear(x) # Internally computes y = xWT + c output is returned\n",
        "\n",
        "# nn.Linear created w and b\n",
        "# PyTorch tracks them automatically"
      ],
      "metadata": {
        "id": "dbM74Xq1HqA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE MODEL & CHECK PARAMETERS\n",
        "\n",
        "model = LinearModel()\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQHGULT5iew5",
        "outputId": "d98ca7fb-13e4-46a9-d2e4-2d4d9ea8dbcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight torch.Size([1, 1])\n",
            "linear.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS FUNCTION & OPTIMIZER\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "Rb0kencEirAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do we pass: model.parameters() to the optimizer? why?\n",
        "\n",
        "Because the optimizer needs to know which learnable tensors (weights and biases) it should update using the computed gradients."
      ],
      "metadata": {
        "id": "gozigXywjm1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING LOOP\n",
        "\n",
        "for epoch in range(1000):\n",
        "    y_pred = model(x)\n",
        "    loss = criterion(y_pred, y)\n",
        "\n",
        "    optimizer.zero_grad()   # reset gradients\n",
        "    loss.backward()         # compute gradients\n",
        "    optimizer.step()        # update weights"
      ],
      "metadata": {
        "id": "GnL77wa8ivQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHY THIS IS BETTER: No manual updates, No manual zeroing per weight, Works for large models, Less bugs"
      ],
      "metadata": {
        "id": "eh1aaKBmjCKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# .train() vs .eval()\n",
        "\n",
        "# When model.train() becomes mandatory\n",
        "# You MUST use it when your model contains:\n",
        "# nn.Dropout\n",
        "# nn.BatchNorm1d / 2d / 3d\n",
        "\n",
        "model.train()  # training mode\n",
        "model.eval()   # inference mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyJA-nhljHPN",
        "outputId": "7cd926c2-6c07-4ac3-8ee1-e34f9646d8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearModel(\n",
              "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SEE FINAL PARAMETERS (WEIGHTS & BIAS)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S9sc_uLjLn0",
        "outputId": "51888b8a-9a84-4ba8-d19e-d82aee3dde3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight tensor([[-0.1993]])\n",
            "linear.bias tensor([0.0653])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST/PREDICT USING THE MODEL\n",
        "\n",
        "model.eval()   # evaluation mode\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_x = torch.tensor([[10.0]])\n",
        "    prediction = model(test_x)\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vbajRgWk63n",
        "outputId": "d3b9d1f7-2612-4b72-f1b1-dfcf4e063c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.9278]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST MULTIPLE VALUES\n",
        "test_x = torch.tensor([[5.0],\n",
        "                       [6.0],\n",
        "                       [7.0]])\n",
        "\n",
        "with torch.no_grad():\n",
        "    print(model(test_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2w--xEXlIwN",
        "outputId": "d207abc2-8c4f-4696-816a-a5d71476fb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9312],\n",
            "        [-1.1305],\n",
            "        [-1.3298]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHY model.eval() + no_grad()?\n",
        "\n",
        "eval() → disables dropout / batchnorm effects\n",
        "\n",
        "no_grad() → faster, no gradient tracking"
      ],
      "metadata": {
        "id": "SEWXZUEZldmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset & DataLoader — HANDLING REAL DATA\n",
        "\n",
        "\n",
        "PyTorch doesn’t want you to manually feed every sample.\n",
        "Dataset + DataLoader make it easy, fast, and batch-friendly.\n",
        "\n"
      ],
      "metadata": {
        "id": "RLQAm6rUvnum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. WHY Dataset?\n",
        "# Represents your entire dataset\n",
        "\n",
        "# Must implement:\n",
        "# __len__() → number of samples\n",
        "# __getitem__() → get one sample"
      ],
      "metadata": {
        "id": "wQIb-qwNxzBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Simple Custom Dataset\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.x = torch.tensor([[1.0],[2.0],[3.0],[4.0]])\n",
        "        self.y = torch.tensor([[3.0],[5.0],[7.0],[9.0]])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "jS2MReJYlfGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2️. DataLoader\n",
        "\n",
        "# Creates batches\n",
        "# Shuffles data\n",
        "# Allows parallel loading"
      ],
      "metadata": {
        "id": "teFDujQqyoVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = MyDataset()\n",
        "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "for xb, yb in loader:\n",
        "    print(xb, yb)\n",
        "\n",
        "# Output (shuffled + batched):\n",
        "\n",
        "# tensor([[2.],[1.]]) tensor([[5.],[3.]])\n",
        "# tensor([[4.],[3.]]) tensor([[9.],[7.]])\n",
        "\n",
        "\n",
        "# WHY USE IT?\n",
        "# Handles batching automatically\n",
        "# Works with GPU easily:\n",
        "\n",
        "for xb, yb in loader:\n",
        "    xb, yb = xb.to(device), yb.to(device) # Load in GPU\n",
        "\n",
        "# Can scale to millions of samples\n",
        "# Supports parallel loading with num_workers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJH4IzcZyuMK",
        "outputId": "653b0262-95f0-45f5-bc5c-c3323c8ef20c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.],\n",
            "        [1.]]) tensor([[5.],\n",
            "        [3.]])\n",
            "tensor([[4.],\n",
            "        [3.]]) tensor([[9.],\n",
            "        [7.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MINI TIP\n",
        "\n",
        "shuffle=True → training only\n",
        "\n",
        "drop_last=True → optional for incomplete last batch\n",
        "\n",
        "batch_size=... → affects convergence\n",
        "\n",
        "\n",
        "=> Why do we not loop over raw tensors for large datasets and instead use DataLoader?\n",
        "\n",
        "Because looping over raw tensors for large datasets is inefficient, memory-heavy, and lacks batching, shuffling, and parallel loading, while DataLoader handles all of that automatically."
      ],
      "metadata": {
        "id": "36Qmm8Qw03-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full example of a simple neural network from scratch"
      ],
      "metadata": {
        "id": "cf65o5HJ2RQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SIMPLE NN FROM SCRATCH\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. LOAD DATA\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data        # features # numpy array of shape (150, 4)\n",
        "y = iris.target      # labels (0,1,2) # numpy array of shape (150,)\n",
        "\n",
        "# 2. TRAIN/VAL/TEST SPLIT\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# 3. STANDARDIZE FEATURES\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 4. CONVERT TO TENSORS\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "# 5. CUSTOM DATASET\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class IrisDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = IrisDataset(X_train, y_train)\n",
        "val_dataset   = IrisDataset(X_val, y_val)\n",
        "test_dataset  = IrisDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "\n",
        "# 6. DEFINE SIMPLE NN\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(4, 16)   # 4 features → hidden 16\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(16, 3)   # 3 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleNN().to(device)\n",
        "\n",
        "# 7. LOSS AND OPTIMIZER\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 8. TRAINING LOOP\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(xb)\n",
        "        loss = criterion(outputs, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # VALIDATION\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            outputs = model(xb)\n",
        "            loss = criterion(outputs, yb)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += yb.size(0)\n",
        "            correct += (predicted == yb).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {running_loss/len(train_loader):.4f} - Val Loss: {val_loss/len(val_loader):.4f} - Val Acc: {correct/total:.4f}\")\n",
        "\n",
        "# 9. TESTING\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        outputs = model(xb)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += yb.size(0)\n",
        "        correct += (predicted == yb).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOLdL3CT2YeC",
        "outputId": "5d05f0ce-f412-47ff-e98e-835a91b2f802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Loss: 0.9240 - Val Loss: 0.6086 - Val Acc: 0.8636\n",
            "Epoch 2/10 - Train Loss: 0.6842 - Val Loss: 0.3558 - Val Acc: 0.9091\n",
            "Epoch 3/10 - Train Loss: 0.5086 - Val Loss: 0.2165 - Val Acc: 0.9091\n",
            "Epoch 4/10 - Train Loss: 0.4322 - Val Loss: 0.1574 - Val Acc: 0.9091\n",
            "Epoch 5/10 - Train Loss: 0.3574 - Val Loss: 0.1319 - Val Acc: 0.9545\n",
            "Epoch 6/10 - Train Loss: 0.3017 - Val Loss: 0.1158 - Val Acc: 0.9545\n",
            "Epoch 7/10 - Train Loss: 0.2686 - Val Loss: 0.0998 - Val Acc: 0.9545\n",
            "Epoch 8/10 - Train Loss: 0.2528 - Val Loss: 0.0804 - Val Acc: 0.9545\n",
            "Epoch 9/10 - Train Loss: 0.2033 - Val Loss: 0.0689 - Val Acc: 1.0000\n",
            "Epoch 10/10 - Train Loss: 0.1985 - Val Loss: 0.0573 - Val Acc: 1.0000\n",
            "Test Accuracy: 0.9565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For CSV"
      ],
      "metadata": {
        "id": "Nuny-gUj9d9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SIMPLE NN FROM CSV\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 1. LOAD CSV\n",
        "df = pd.read_csv(\"iris.csv\")  # replace with your CSV path\n",
        "\n",
        "# 2. SPLIT FEATURES & LABEL\n",
        "X = df.drop(\"class\", axis=1).values  # numpy array\n",
        "y = df[\"class\"].values               # numpy array\n",
        "\n",
        "############ Converted to Numpy Array - Rest is same #############\n",
        "\n",
        "\n",
        "# 3. TRAIN / VAL / TEST SPLIT\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# 4. STANDARDIZE FEATURES\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val   = scaler.transform(X_val)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# 5. CONVERT TO TORCH TENSORS\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# 6. CREATE CUSTOM DATASET\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = MyDataset(X_train, y_train)\n",
        "val_dataset   = MyDataset(X_val, y_val)\n",
        "test_dataset  = MyDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Rest Same..."
      ],
      "metadata": {
        "id": "eunIA-zs9UPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN (Convolutional Neural Networks) FROM SCRATCH"
      ],
      "metadata": {
        "id": "RxRf0QoY_kpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN FOR MNIST\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. DATASET & DATALOADER\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset  = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# 3. CNN MODEL\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool  = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(16,32,3,padding=1)\n",
        "        self.fc1   = nn.Linear(32*7*7, 128)\n",
        "        self.fc2   = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "# 4. LOSS & OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 5. TRAINING LOOP\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(xb)\n",
        "        loss = criterion(outputs, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# 6. TESTING\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        outputs = model(xb)\n",
        "        _, predicted = torch.max(outputs,1)\n",
        "        total += yb.size(0)\n",
        "        correct += (predicted == yb).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {correct/total:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inQuvHmR_KNF",
        "outputId": "ed199eff-2edb-4c03-c256-44743d88fbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 4.98MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 132kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 13.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 0.2106\n",
            "Epoch 2/5 - Loss: 0.0542\n",
            "Epoch 3/5 - Loss: 0.0403\n",
            "Epoch 4/5 - Loss: 0.0297\n",
            "Epoch 5/5 - Loss: 0.0243\n",
            "Test Accuracy: 0.9894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With Validation"
      ],
      "metadata": {
        "id": "L5CvirbVCjRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN FOR MNIST WITH TRAIN/VAL/TEST SPLIT\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 1. DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. DATASET & SPLIT\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # Convert PIL Image or NumPy ndarray to PyTorch tensor\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize tensor values | formula: (x - mean)/std | here mean=0.5, std=0.5 for single channel | scales values from [0,1] → [-1,1]\n",
        "])\n",
        "\n",
        "# transforms.ToTensor()  # converts image → tensor\n",
        "# Original image: (H, W) = (28, 28)\n",
        "# After ToTensor: (C, H, W) = (1, 28, 28)\n",
        "# C = channels (1 for grayscale, 3 for RGB)\n",
        "# Pixel values scaled: 0–255 → 0.0–1.0\n",
        "\n",
        "full_train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset       = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "# Split full_train_dataset into train + val\n",
        "train_size = int(0.9 * len(full_train_dataset))\n",
        "val_size   = len(full_train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
        "\n",
        "# In the MNIST CNN example, we didn’t use a custom Dataset because:\n",
        "# torchvision.datasets.MNIST already provides a ready-to-use Dataset:\n",
        "# It implements __len__() and __getitem__() internally.\n",
        "# It supports transform automatically.\n",
        "\n",
        "# 3. DATALOADERS\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=64)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# 4. CNN MODEL\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1) # 1 → input channel (grayscale) 1x28x28 -> 16x28x28, 16 filters extract features\n",
        "        self.pool  = nn.MaxPool2d(2,2) # 16x28x28 -> 16x14x14, downsample by 2\n",
        "        self.conv2 = nn.Conv2d(16,32,3,padding=1) # 16x14x14 -> 32x14x14, 32 filters learn deeper features\n",
        "        self.fc1   = nn.Linear(32*7*7, 128) # 32x7x7 flattened -> 128, dense features\n",
        "        self.fc2   = nn.Linear(128, 10) # 128 -> 10 classes (0-9 digits)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x)) # Conv1: 1x28x28 -> 16x28x28, extract 16 feature maps\n",
        "        x = self.pool(x) # MaxPool: 16x28x28 -> 16x14x14, downsample by 2\n",
        "        x = F.relu(self.conv2(x)) # Conv2: 16x14x14 -> 32x14x14, extract 32 deeper features\n",
        "        x = self.pool(x)  # MaxPool: 32x14x14 -> 32x7x7, downsample by 2\n",
        "        x = x.view(x.size(0), -1) # Flatten: 32x7x7 -> 1568, prepare for fully connected\n",
        "        x = F.relu(self.fc1(x)) # FC1: 1568 -> 128, learn dense feature combinations\n",
        "        x = self.fc2(x) # FC2: 128 -> 10, output class scores for digits 0-9\n",
        "        return x\n",
        "\n",
        "# x.view(x.size(0), -1) details\n",
        "\n",
        "# x.shape = (batch_size, channels, height, width)\n",
        "# x.shape before flatten = (64, 32, 7, 7) as train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "# x.shape before flatten = (64, 32, 7, 7)\n",
        "\n",
        "# x.size(0) = batch_size\n",
        "# x.size(0) = 64\n",
        "# x.view(x.size(0), -1) → (64, 1568)\n",
        "# Result after flatten: (64, 1568)\n",
        "# Each row = one image flattened  [each image is a row]\n",
        "# Now ready for fully connected layer: (64, 1568) → 128 → 10\n",
        "\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "# 5. LOSS & OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 6. TRAINING LOOP WITH VALIDATION\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    # TRAIN\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(xb)\n",
        "        loss = criterion(outputs, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # VALIDATION\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            outputs = model(xb)\n",
        "            loss = criterion(outputs, yb)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += yb.size(0)\n",
        "            correct += (predicted == yb).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - \"\n",
        "          f\"Train Loss: {running_loss/len(train_loader):.4f} - \"\n",
        "          f\"Val Loss: {val_loss/len(val_loader):.4f} - \"\n",
        "          f\"Val Acc: {correct/total:.4f}\")\n",
        "\n",
        "# 7. TESTING\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        outputs = model(xb)\n",
        "        _, predicted = torch.max(outputs,1)\n",
        "        total += yb.size(0)\n",
        "        correct += (predicted == yb).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {correct/total:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45RgqVvCClFh",
        "outputId": "b2893dbc-37bc-4a79-f668-deb4bafb0841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.2226 - Val Loss: 0.0891 - Val Acc: 0.9737\n",
            "Epoch 2/5 - Train Loss: 0.0583 - Val Loss: 0.0537 - Val Acc: 0.9837\n",
            "Epoch 3/5 - Train Loss: 0.0418 - Val Loss: 0.0572 - Val Acc: 0.9835\n",
            "Epoch 4/5 - Train Loss: 0.0313 - Val Loss: 0.0465 - Val Acc: 0.9857\n",
            "Epoch 5/5 - Train Loss: 0.0258 - Val Loss: 0.0422 - Val Acc: 0.9872\n",
            "Test Accuracy: 0.9898\n"
          ]
        }
      ]
    }
  ]
}